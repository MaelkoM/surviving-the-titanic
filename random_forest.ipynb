{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1313,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 1314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv', sep=\",\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show which columns contain NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN in PassengerId: False\n",
      "NaN in Survived: False\n",
      "NaN in Pclass: False\n",
      "NaN in Name: False\n",
      "NaN in Sex: False\n",
      "NaN in Age: True\n",
      "NaN in SibSp: False\n",
      "NaN in Parch: False\n",
      "NaN in Ticket: False\n",
      "NaN in Fare: False\n",
      "NaN in Cabin: True\n",
      "NaN in Embarked: True\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    print(f\"NaN in {column}:\", df[column].isna().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneHotEncoder for Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1316,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df,prefix=['Sex'], columns = ['Sex'], drop_first=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline of OHE and Imputation for Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1317,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "impute_and_encode = make_pipeline(SimpleImputer(strategy='most_frequent'),\n",
    "                                  OneHotEncoder(sparse=False)\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1318,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_and_encode.fit(df[[\"Embarked\"]])\n",
    "t = impute_and_encode.transform(df[[\"Embarked\"]])\n",
    "embarked_matrix = pd.DataFrame(t, columns=impute_and_encode[1].get_feature_names())\n",
    "df = pd.concat([df, embarked_matrix], axis=1).drop([\"Embarked\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1323,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Fare\"] = np.log(df[\"Fare\"] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2.110213\n",
       "1      4.280593\n",
       "2      2.188856\n",
       "3      3.990834\n",
       "4      2.202765\n",
       "         ...   \n",
       "886    2.639057\n",
       "887    3.433987\n",
       "888    3.196630\n",
       "889    3.433987\n",
       "890    2.169054\n",
       "Name: Fare, Length: 891, dtype: float64"
      ]
     },
     "execution_count": 1324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Fare\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1325,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rank'] = df['Name'].str.split('([A-Za-z]+)(\\.)', expand=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1326,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df[\"rank\"].unique().tolist()\n",
    "rank = [3,2,1,7,7,4,4,2,2,7,5,6,1,7,7,5,7]\n",
    "rank = [3,2,1,9,10,4,5,2,2,11,6,8,1,12,13,7,14]\n",
    "dic = {}\n",
    "for title, rank in zip(titles, rank):\n",
    "    dic[title] = rank\n",
    "df[\"rank\"].replace(dic, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1327,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1328,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Cabin\"] = df[\"Cabin\"].fillna(\"Z0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1329,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df[\"Cabin\"].astype(str).str[0]\n",
    "df[\"deck\"] = result.replace({\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"T\": 1, \"Z\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1330,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cabin_number\"] = df[\"Cabin\"].str.split('([A-Za-z]+)(\\d+)', expand=True)[2]\n",
    "df[\"cabin_number\"].fillna(\"0\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation for Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1331,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row, value in df.loc[df[\"Age\"] != type(float)][\"Pclass\"].iteritems():\n",
    "    df.loc[row, \"Age\"] = df.loc[df[\"Pclass\"] == value][\"Age\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1334,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>x0_C</th>\n",
       "      <th>x0_Q</th>\n",
       "      <th>x0_S</th>\n",
       "      <th>rank</th>\n",
       "      <th>deck</th>\n",
       "      <th>cabin_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>2.110213</td>\n",
       "      <td>Z0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>4.280593</td>\n",
       "      <td>C85</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>2.188856</td>\n",
       "      <td>Z0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>3.990834</td>\n",
       "      <td>C123</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>2.202765</td>\n",
       "      <td>Z0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>Z0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>B42</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>3.196630</td>\n",
       "      <td>Z0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>C148</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>2.169054</td>\n",
       "      <td>Z0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name   Age  SibSp  Parch  \\\n",
       "0                              Braund, Mr. Owen Harris  24.0      1      0   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  37.0      1      0   \n",
       "2                               Heikkinen, Miss. Laina  24.0      0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  37.0      1      0   \n",
       "4                             Allen, Mr. William Henry  24.0      0      0   \n",
       "..                                                 ...   ...    ...    ...   \n",
       "886                              Montvila, Rev. Juozas  29.0      0      0   \n",
       "887                       Graham, Miss. Margaret Edith  37.0      0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  24.0      1      2   \n",
       "889                              Behr, Mr. Karl Howell  37.0      0      0   \n",
       "890                                Dooley, Mr. Patrick  24.0      0      0   \n",
       "\n",
       "               Ticket      Fare Cabin  Sex_male  x0_C  x0_Q  x0_S  rank  deck  \\\n",
       "0           A/5 21171  2.110213    Z0         1   0.0   0.0   1.0     3     4   \n",
       "1            PC 17599  4.280593   C85         0   1.0   0.0   0.0     2     3   \n",
       "2    STON/O2. 3101282  2.188856    Z0         0   0.0   0.0   1.0     1     4   \n",
       "3              113803  3.990834  C123         0   0.0   0.0   1.0     2     3   \n",
       "4              373450  2.202765    Z0         1   0.0   0.0   1.0     3     4   \n",
       "..                ...       ...   ...       ...   ...   ...   ...   ...   ...   \n",
       "886            211536  2.639057    Z0         1   0.0   0.0   1.0     4     4   \n",
       "887            112053  3.433987   B42         0   0.0   0.0   1.0     1     2   \n",
       "888        W./C. 6607  3.196630    Z0         0   0.0   0.0   1.0     1     4   \n",
       "889            111369  3.433987  C148         1   1.0   0.0   0.0     3     3   \n",
       "890            370376  2.169054    Z0         1   0.0   1.0   0.0     3     4   \n",
       "\n",
       "    cabin_number  \n",
       "0              0  \n",
       "1             85  \n",
       "2              0  \n",
       "3            123  \n",
       "4              0  \n",
       "..           ...  \n",
       "886            0  \n",
       "887           42  \n",
       "888            0  \n",
       "889          148  \n",
       "890            0  \n",
       "\n",
       "[891 rows x 17 columns]"
      ]
     },
     "execution_count": 1334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "x = df[[\"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Sex_male\", \"Fare\"]].values #returns a numpy array\n",
    "min_max_scaler = StandardScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df = pd.concat([df.drop([\"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Sex_male\", \"Fare\"], axis=1), pd.DataFrame(x_scaled, columns=[\"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Sex_male\", \"Fare\"])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Feature Matrix and the Target Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8652849740932642\n",
      "sklearn_score 0.833\n"
     ]
    }
   ],
   "source": [
    "# X = df[[\"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Sex_male\", \"Fare\", \"rank\", \"cabin_number\", \"deck\", \"x0_C\", \"x0_Q\", \"x0_S\"]]\n",
    "X = df[[\"rank\", \"Sex_male\", \"SibSp\", \"cabin_number\"]]\n",
    "y = df['Survived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, train_size=0.65, test_size=0.35)\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "sklearn_score = clf.score(X_test, y_test)\n",
    "print(\"sklearn_score\", round(sklearn_score, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>deck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank  Sex_male  SibSp  deck\n",
       "0     3         1      1     4\n",
       "1     2         0      1     3\n",
       "2     1         0      0     4\n",
       "3     2         0      1     3\n",
       "4     3         1      0     4"
      ]
     },
     "execution_count": 1373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting X and y into test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1384,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, train_size=0.65, test_size=0.35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1376,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8238341968911918\n",
      "sklearn_score 0.827\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(criterion='entropy', max_depth=4, max_features='log2',\n",
    "                       n_estimators=20, n_jobs=-1, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "sklearn_score = clf.score(X_test, y_test)\n",
    "print(\"sklearn_score\", round(sklearn_score, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f7689a21910>"
      ]
     },
     "execution_count": 1378,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(clf, X_test, y_test, cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6025641025641025"
      ]
     },
     "execution_count": 1381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "dummy_accuracy = accuracy_score(dummy_clf.predict(X_test), y_test)\n",
    "dummy_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0' 3]\n",
      " ['0' 3]\n",
      " ['0' 3]\n",
      " ...\n",
      " ['0' 3]\n",
      " ['96' 1]\n",
      " ['26' 3]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X must be an integer or float array. Found object.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1386-c20c217d7b0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mya\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_decision_regions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mya\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Decision Boundary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cabin_number\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/mlxtend/plotting/decision_regions.py\u001b[0m in \u001b[0;36mplot_decision_regions\u001b[0;34m(X, y, clf, feature_index, filler_feature_values, filler_feature_ranges, ax, X_highlight, res, zoom_factor, legend, hide_spines, markers, colors, scatter_kwargs, contourf_kwargs, scatter_highlight_kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \"\"\"\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mcheck_Xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Validate X and y arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/mlxtend/utils/checking.py\u001b[0m in \u001b[0;36mcheck_Xy\u001b[0;34m(X, y, y_int)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'int'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         raise ValueError('X must be an integer or float array. Found %s.'\n\u001b[0m\u001b[1;32m     27\u001b[0m                          % X.dtype)\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X must be an integer or float array. Found object."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "\n",
    "Xa=X_train[[\"cabin_number\", \"rank\"]].to_numpy()\n",
    "ya=y_train.to_numpy()\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "for t in zip([clf]):\n",
    "    clf.fit(Xa, ya)\n",
    "    fig = plot_decision_regions(X=Xa, y=ya, clf=clf, legend=1)\n",
    "plt.title('Decision Boundary', fontsize=17)\n",
    "plt.xlabel(\"cabin_number\", fontsize=15)\n",
    "plt.ylabel(\"rank\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1296,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est = [500, 800, 1500]\n",
    "max_feat = [\"auto\", \"sqrt\", \"log2\"]\n",
    "max_depth = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10, 15, 20]\n",
    "min_samples_leaf = [1, 2, 5, 10, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1297,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = {\"n_estimators\": n_est,\n",
    "           \"max_features\": max_feat,\n",
    "            \"max_depth\": max_depth,\n",
    "            \"min_samples_split\": min_samples_split,\n",
    "            \"min_samples_leaf\": min_samples_leaf  \n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 500 candidates, totalling 1000 fits\n",
      "{'n_estimators': 800, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 15}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf_random = RandomizedSearchCV(estimator=clf, param_distributions=grid_param, n_iter=500, cv=2, verbose=2, random_state=42, n_jobs=-1)\n",
    "clf_random.fit(X_train, y_train)\n",
    "print(clf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8071748878923767\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_random.predict(X_test)\n",
    "accuracy = clf_random.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 1 0.7847533632286996\n",
      "---------------------------> 0.7847533632286996 0.600896860986547 0\n",
      "1 3 2 0.7982062780269058\n",
      "---------------------------> 0.7982062780269058 0.7847533632286996 RandomForestClassifier(criterion='entropy', max_depth=2, max_features='log2',\n",
      "                       n_estimators=10, n_jobs=-1, random_state=42)\n",
      "1 4 3 0.7982062780269058\n",
      "0.7982062780269058\n",
      "1 5 4 0.8071748878923767\n",
      "---------------------------> 0.8071748878923767 0.7982062780269058 RandomForestClassifier(criterion='entropy', max_depth=3, max_features='log2',\n",
      "                       n_estimators=10, n_jobs=-1, random_state=42)\n",
      "1 6 5 0.8071748878923767\n",
      "0.8071748878923767\n",
      "1 7 6 0.8116591928251121\n",
      "---------------------------> 0.8116591928251121 0.8071748878923767 RandomForestClassifier(criterion='entropy', max_depth=5, max_features='log2',\n",
      "                       n_estimators=10, n_jobs=-1, random_state=42)\n",
      "1 8 7 0.8116591928251121\n",
      "0.8116591928251121\n",
      "1 9 8 0.8116591928251121\n",
      "0.8116591928251121\n",
      "1 10 9 0.8116591928251121\n",
      "0.8116591928251121\n",
      "1 11 10 0.8116591928251121\n",
      "0.8116591928251121\n",
      "1 12 11 0.8116591928251121\n",
      "0.8116591928251121\n",
      "1 13 12 0.8116591928251121\n",
      "0.8116591928251121\n",
      "1 14 13 0.8116591928251121\n",
      "0.8116591928251121\n",
      "2 2 14 0.7847533632286996\n",
      "2 3 15 0.7982062780269058\n",
      "2 4 16 0.820627802690583\n",
      "---------------------------> 0.820627802690583 0.8116591928251121 RandomForestClassifier(criterion='entropy', max_depth=7, max_features='log2',\n",
      "                       n_estimators=10, n_jobs=-1, random_state=42)\n",
      "2 5 17 0.8071748878923767\n",
      "0.8071748878923767\n",
      "2 6 18 0.8071748878923767\n",
      "0.8071748878923767\n",
      "2 7 19 0.8071748878923767\n",
      "0.8071748878923767\n",
      "2 8 20 0.8116591928251121\n",
      "0.8116591928251121\n",
      "2 9 21 0.8071748878923767\n",
      "0.8071748878923767\n",
      "2 10 22 0.8071748878923767\n",
      "0.8071748878923767\n",
      "2 11 23 0.8071748878923767\n",
      "0.8071748878923767\n",
      "2 12 24 0.8071748878923767\n",
      "0.8071748878923767\n",
      "2 13 25 0.8071748878923767\n",
      "0.8071748878923767\n",
      "2 14 26 0.8071748878923767\n",
      "0.8071748878923767\n",
      "3 2 27 0.7847533632286996\n",
      "3 3 28 0.820627802690583\n",
      "3 4 29 0.820627802690583\n",
      "0.820627802690583\n",
      "3 5 30 0.8071748878923767\n",
      "0.8071748878923767\n",
      "3 6 31 0.8071748878923767\n",
      "0.8071748878923767\n",
      "3 7 32 0.8071748878923767\n",
      "0.8071748878923767\n",
      "3 8 33 0.8116591928251121\n",
      "0.8116591928251121\n",
      "3 9 34 0.8116591928251121\n",
      "0.8116591928251121\n",
      "3 10 35 0.8116591928251121\n",
      "0.8116591928251121\n",
      "3 11 36 0.8116591928251121\n",
      "0.8116591928251121\n",
      "3 12 37 0.8116591928251121\n",
      "0.8116591928251121\n",
      "3 13 38 0.8116591928251121\n",
      "0.8116591928251121\n",
      "3 14 39 0.8116591928251121\n",
      "0.8116591928251121\n",
      "4 2 40 0.7847533632286996\n",
      "4 3 41 0.8071748878923767\n",
      "4 4 42 0.8071748878923767\n",
      "0.8071748878923767\n",
      "4 5 43 0.8071748878923767\n",
      "0.8071748878923767\n",
      "4 6 44 0.8071748878923767\n",
      "0.8071748878923767\n",
      "4 7 45 0.8116591928251121\n",
      "4 8 46 0.8116591928251121\n",
      "0.8116591928251121\n",
      "4 9 47 0.8116591928251121\n",
      "0.8116591928251121\n",
      "4 10 48 0.8116591928251121\n",
      "0.8116591928251121\n",
      "4 11 49 0.8116591928251121\n",
      "0.8116591928251121\n",
      "4 12 50 0.8116591928251121\n",
      "0.8116591928251121\n",
      "4 13 51 0.8116591928251121\n",
      "0.8116591928251121\n",
      "4 14 52 0.8116591928251121\n",
      "0.8116591928251121\n",
      "5 2 53 0.7847533632286996\n",
      "5 3 54 0.7847533632286996\n",
      "0.7847533632286996\n",
      "5 4 55 0.8071748878923767\n",
      "5 5 56 0.8071748878923767\n",
      "0.8071748878923767\n",
      "5 6 57 0.8071748878923767\n",
      "0.8071748878923767\n",
      "5 7 58 0.8116591928251121\n",
      "5 8 59 0.8116591928251121\n",
      "0.8116591928251121\n",
      "5 9 60 0.8116591928251121\n",
      "0.8116591928251121\n",
      "5 10 61 0.8116591928251121\n",
      "0.8116591928251121\n",
      "5 11 62 0.8116591928251121\n",
      "0.8116591928251121\n",
      "5 12 63 0.8116591928251121\n",
      "0.8116591928251121\n",
      "5 13 64 0.8116591928251121\n",
      "0.8116591928251121\n",
      "5 14 65 0.8116591928251121\n",
      "0.8116591928251121\n",
      "6 2 66 0.7847533632286996\n",
      "6 3 67 0.7892376681614349\n",
      "6 4 68 0.820627802690583\n",
      "6 5 69 0.8071748878923767\n",
      "0.8071748878923767\n",
      "6 6 70 0.8071748878923767\n",
      "0.8071748878923767\n",
      "6 7 71 0.8116591928251121\n",
      "0.8116591928251121\n",
      "6 8 72 0.8116591928251121\n",
      "0.8116591928251121\n",
      "6 9 73 0.8116591928251121\n",
      "0.8116591928251121\n",
      "6 10 74 0.8116591928251121\n",
      "0.8116591928251121\n",
      "6 11 75 0.8116591928251121\n",
      "0.8116591928251121\n",
      "6 12 76 0.8116591928251121\n",
      "0.8116591928251121\n",
      "6 13 77 0.8116591928251121\n",
      "0.8116591928251121\n",
      "6 14 78 0.8116591928251121\n",
      "0.8116591928251121\n",
      "7 2 79 0.7847533632286996\n",
      "7 3 80 0.8071748878923767\n",
      "7 4 81 0.8071748878923767\n",
      "0.8071748878923767\n",
      "7 5 82 0.8071748878923767\n",
      "0.8071748878923767\n",
      "7 6 83 0.8071748878923767\n",
      "0.8071748878923767\n",
      "7 7 84 0.8116591928251121\n",
      "7 8 85 0.8116591928251121\n",
      "0.8116591928251121\n",
      "7 9 86 0.8116591928251121\n",
      "0.8116591928251121\n",
      "7 10 87 0.8116591928251121\n",
      "0.8116591928251121\n",
      "7 11 88 0.8116591928251121\n",
      "0.8116591928251121\n",
      "7 12 89 0.8116591928251121\n",
      "0.8116591928251121\n",
      "7 13 90 0.8116591928251121\n",
      "0.8116591928251121\n",
      "7 14 91 0.8116591928251121\n",
      "0.8116591928251121\n",
      "8 2 92 0.7847533632286996\n",
      "8 3 93 0.7982062780269058\n",
      "8 4 94 0.8071748878923767\n",
      "8 5 95 0.8071748878923767\n",
      "0.8071748878923767\n",
      "8 6 96 0.8116591928251121\n",
      "8 7 97 0.8116591928251121\n",
      "0.8116591928251121\n",
      "8 8 98 0.8116591928251121\n",
      "0.8116591928251121\n",
      "8 9 99 0.8116591928251121\n",
      "0.8116591928251121\n",
      "8 10 100 0.8116591928251121\n",
      "0.8116591928251121\n",
      "8 11 101 0.8116591928251121\n",
      "0.8116591928251121\n",
      "8 12 102 0.8116591928251121\n",
      "0.8116591928251121\n",
      "8 13 103 0.8116591928251121\n",
      "0.8116591928251121\n",
      "8 14 104 0.8116591928251121\n",
      "0.8116591928251121\n",
      "9 2 105 0.7847533632286996\n",
      "9 3 106 0.7982062780269058\n",
      "9 4 107 0.820627802690583\n",
      "9 5 108 0.8116591928251121\n",
      "0.8116591928251121\n",
      "9 6 109 0.8116591928251121\n",
      "0.8116591928251121\n",
      "9 7 110 0.8116591928251121\n",
      "0.8116591928251121\n",
      "9 8 111 0.8116591928251121\n",
      "0.8116591928251121\n",
      "9 9 112 0.8116591928251121\n",
      "0.8116591928251121\n",
      "9 10 113 0.8116591928251121\n",
      "0.8116591928251121\n",
      "9 11 114 0.8116591928251121\n",
      "0.8116591928251121\n",
      "9 12 115 0.8116591928251121\n",
      "0.8116591928251121\n",
      "9 13 116 0.8116591928251121\n",
      "0.8116591928251121\n",
      "9 14 117 0.8116591928251121\n",
      "0.8116591928251121\n",
      "10 2 118 0.7847533632286996\n",
      "10 3 119 0.8026905829596412\n",
      "10 4 120 0.820627802690583\n",
      "10 5 121 0.8116591928251121\n",
      "0.8116591928251121\n",
      "10 6 122 0.8116591928251121\n",
      "0.8116591928251121\n",
      "10 7 123 0.8116591928251121\n",
      "0.8116591928251121\n",
      "10 8 124 0.8116591928251121\n",
      "0.8116591928251121\n",
      "10 9 125 0.8116591928251121\n",
      "0.8116591928251121\n",
      "10 10 126 0.8116591928251121\n",
      "0.8116591928251121\n",
      "10 11 127 0.8116591928251121\n",
      "0.8116591928251121\n",
      "10 12 128 0.8116591928251121\n",
      "0.8116591928251121\n",
      "10 13 129 0.8116591928251121\n",
      "0.8116591928251121\n",
      "10 14 130 0.8116591928251121\n",
      "0.8116591928251121\n",
      "11 2 131 0.7847533632286996\n",
      "11 3 132 0.820627802690583\n",
      "11 4 133 0.820627802690583\n",
      "0.820627802690583\n",
      "11 5 134 0.8116591928251121\n",
      "0.8116591928251121\n",
      "11 6 135 0.8116591928251121\n",
      "0.8116591928251121\n",
      "11 7 136 0.8116591928251121\n",
      "0.8116591928251121\n",
      "11 8 137 0.8116591928251121\n",
      "0.8116591928251121\n",
      "11 9 138 0.8116591928251121\n",
      "0.8116591928251121\n",
      "11 10 139 0.8116591928251121\n",
      "0.8116591928251121\n",
      "11 11 140 0.8116591928251121\n",
      "0.8116591928251121\n",
      "11 12 141 0.8116591928251121\n",
      "0.8116591928251121\n",
      "11 13 142 0.8116591928251121\n",
      "0.8116591928251121\n",
      "11 14 143 0.8116591928251121\n",
      "0.8116591928251121\n",
      "12 2 144 0.7847533632286996\n",
      "12 3 145 0.8071748878923767\n",
      "12 4 146 0.820627802690583\n",
      "12 5 147 0.8116591928251121\n",
      "0.8116591928251121\n",
      "12 6 148 0.8116591928251121\n",
      "0.8116591928251121\n",
      "12 7 149 0.8116591928251121\n",
      "0.8116591928251121\n",
      "12 8 150 0.8116591928251121\n",
      "0.8116591928251121\n",
      "12 9 151 0.8116591928251121\n",
      "0.8116591928251121\n",
      "12 10 152 0.8116591928251121\n",
      "0.8116591928251121\n",
      "12 11 153 0.8116591928251121\n",
      "0.8116591928251121\n",
      "12 12 154 0.8116591928251121\n",
      "0.8116591928251121\n",
      "12 13 155 0.8116591928251121\n",
      "0.8116591928251121\n",
      "12 14 156 0.8116591928251121\n",
      "0.8116591928251121\n",
      "13 2 157 0.7847533632286996\n",
      "13 3 158 0.820627802690583\n",
      "13 4 159 0.820627802690583\n",
      "0.820627802690583\n",
      "13 5 160 0.8116591928251121\n",
      "0.8116591928251121\n",
      "13 6 161 0.8116591928251121\n",
      "0.8116591928251121\n",
      "13 7 162 0.8116591928251121\n",
      "0.8116591928251121\n",
      "13 8 163 0.8116591928251121\n",
      "0.8116591928251121\n",
      "13 9 164 0.8116591928251121\n",
      "0.8116591928251121\n",
      "13 10 165 0.8116591928251121\n",
      "0.8116591928251121\n",
      "13 11 166 0.8116591928251121\n",
      "0.8116591928251121\n",
      "13 12 167 0.8116591928251121\n",
      "0.8116591928251121\n",
      "13 13 168 0.8116591928251121\n",
      "0.8116591928251121\n",
      "13 14 169 0.8116591928251121\n",
      "0.8116591928251121\n",
      "14 2 170 0.7847533632286996\n",
      "14 3 171 0.820627802690583\n",
      "14 4 172 0.820627802690583\n",
      "0.820627802690583\n",
      "14 5 173 0.8116591928251121\n",
      "0.8116591928251121\n",
      "14 6 174 0.8116591928251121\n",
      "0.8116591928251121\n",
      "14 7 175 0.8116591928251121\n",
      "0.8116591928251121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 8 176 0.8116591928251121\n",
      "0.8116591928251121\n",
      "14 9 177 0.8116591928251121\n",
      "0.8116591928251121\n",
      "14 10 178 0.8116591928251121\n",
      "0.8116591928251121\n",
      "14 11 179 0.8116591928251121\n",
      "0.8116591928251121\n",
      "14 12 180 0.8116591928251121\n",
      "0.8116591928251121\n",
      "14 13 181 0.8116591928251121\n",
      "0.8116591928251121\n",
      "14 14 182 0.8116591928251121\n",
      "0.8116591928251121\n",
      "15 2 183 0.7847533632286996\n",
      "15 3 184 0.820627802690583\n",
      "15 4 185 0.820627802690583\n",
      "0.820627802690583\n",
      "15 5 186 0.8116591928251121\n",
      "0.8116591928251121\n",
      "15 6 187 0.8116591928251121\n",
      "0.8116591928251121\n",
      "15 7 188 0.8116591928251121\n",
      "0.8116591928251121\n",
      "15 8 189 0.8116591928251121\n",
      "0.8116591928251121\n",
      "15 9 190 0.8116591928251121\n",
      "0.8116591928251121\n",
      "15 10 191 0.8116591928251121\n",
      "0.8116591928251121\n",
      "15 11 192 0.8116591928251121\n",
      "0.8116591928251121\n",
      "15 12 193 0.8116591928251121\n",
      "0.8116591928251121\n",
      "15 13 194 0.8116591928251121\n",
      "0.8116591928251121\n",
      "15 14 195 0.8116591928251121\n",
      "0.8116591928251121\n",
      "16 2 196 0.7847533632286996\n",
      "16 3 197 0.820627802690583\n",
      "16 4 198 0.820627802690583\n",
      "0.820627802690583\n",
      "16 5 199 0.8116591928251121\n",
      "0.8116591928251121\n",
      "16 6 200 0.8116591928251121\n",
      "0.8116591928251121\n",
      "16 7 201 0.8116591928251121\n",
      "0.8116591928251121\n",
      "16 8 202 0.8116591928251121\n",
      "0.8116591928251121\n",
      "16 9 203 0.8116591928251121\n",
      "0.8116591928251121\n",
      "16 10 204 0.8116591928251121\n",
      "0.8116591928251121\n",
      "16 11 205 0.8116591928251121\n",
      "0.8116591928251121\n",
      "16 12 206 0.8116591928251121\n",
      "0.8116591928251121\n",
      "16 13 207 0.8116591928251121\n",
      "0.8116591928251121\n",
      "16 14 208 0.8116591928251121\n",
      "0.8116591928251121\n",
      "17 2 209 0.7847533632286996\n",
      "17 3 210 0.820627802690583\n",
      "17 4 211 0.820627802690583\n",
      "0.820627802690583\n",
      "17 5 212 0.8116591928251121\n",
      "0.8116591928251121\n",
      "17 6 213 0.8116591928251121\n",
      "0.8116591928251121\n",
      "17 7 214 0.8116591928251121\n",
      "0.8116591928251121\n",
      "17 8 215 0.8116591928251121\n",
      "0.8116591928251121\n",
      "17 9 216 0.8116591928251121\n",
      "0.8116591928251121\n",
      "17 10 217 0.8116591928251121\n",
      "0.8116591928251121\n",
      "17 11 218 0.8116591928251121\n",
      "0.8116591928251121\n",
      "17 12 219 0.8116591928251121\n",
      "0.8116591928251121\n",
      "17 13 220 0.8116591928251121\n",
      "0.8116591928251121\n",
      "17 14 221 0.8116591928251121\n",
      "0.8116591928251121\n",
      "18 2 222 0.7847533632286996\n",
      "18 3 223 0.820627802690583\n",
      "18 4 224 0.820627802690583\n",
      "0.820627802690583\n",
      "18 5 225 0.8116591928251121\n",
      "0.8116591928251121\n",
      "18 6 226 0.8116591928251121\n",
      "0.8116591928251121\n",
      "18 7 227 0.8116591928251121\n",
      "0.8116591928251121\n",
      "18 8 228 0.8116591928251121\n",
      "0.8116591928251121\n",
      "18 9 229 0.8116591928251121\n",
      "0.8116591928251121\n",
      "18 10 230 0.8116591928251121\n",
      "0.8116591928251121\n",
      "18 11 231 0.8116591928251121\n",
      "0.8116591928251121\n",
      "18 12 232 0.8116591928251121\n",
      "0.8116591928251121\n",
      "18 13 233 0.8116591928251121\n",
      "0.8116591928251121\n",
      "18 14 234 0.8116591928251121\n",
      "0.8116591928251121\n",
      "19 2 235 0.7847533632286996\n",
      "19 3 236 0.820627802690583\n",
      "19 4 237 0.820627802690583\n",
      "0.820627802690583\n",
      "19 5 238 0.8116591928251121\n",
      "0.8116591928251121\n",
      "19 6 239 0.8116591928251121\n",
      "0.8116591928251121\n",
      "19 7 240 0.8116591928251121\n",
      "0.8116591928251121\n",
      "19 8 241 0.8116591928251121\n",
      "0.8116591928251121\n",
      "19 9 242 0.8116591928251121\n",
      "0.8116591928251121\n",
      "19 10 243 0.8116591928251121\n",
      "0.8116591928251121\n",
      "19 11 244 0.8116591928251121\n",
      "0.8116591928251121\n",
      "19 12 245 0.8116591928251121\n",
      "0.8116591928251121\n",
      "19 13 246 0.8116591928251121\n",
      "0.8116591928251121\n",
      "19 14 247 0.8116591928251121\n",
      "0.8116591928251121\n",
      "20 2 248 0.7847533632286996\n",
      "20 3 249 0.820627802690583\n",
      "20 4 250 0.820627802690583\n",
      "0.820627802690583\n",
      "20 5 251 0.8116591928251121\n",
      "0.8116591928251121\n",
      "20 6 252 0.8116591928251121\n",
      "0.8116591928251121\n",
      "20 7 253 0.8116591928251121\n",
      "0.8116591928251121\n",
      "20 8 254 0.8116591928251121\n",
      "0.8116591928251121\n",
      "20 9 255 0.8116591928251121\n",
      "0.8116591928251121\n",
      "20 10 256 0.8116591928251121\n",
      "0.8116591928251121\n",
      "20 11 257 0.8116591928251121\n",
      "0.8116591928251121\n",
      "20 12 258 0.8116591928251121\n",
      "0.8116591928251121\n",
      "20 13 259 0.8116591928251121\n",
      "0.8116591928251121\n",
      "20 14 260 0.8116591928251121\n",
      "0.8116591928251121\n",
      "21 2 261 0.7847533632286996\n",
      "21 3 262 0.820627802690583\n",
      "21 4 263 0.820627802690583\n",
      "0.820627802690583\n",
      "21 5 264 0.8071748878923767\n",
      "0.8071748878923767\n",
      "21 6 265 0.8116591928251121\n",
      "0.8116591928251121\n",
      "21 7 266 0.8116591928251121\n",
      "0.8116591928251121\n",
      "21 8 267 0.8116591928251121\n",
      "0.8116591928251121\n",
      "21 9 268 0.8116591928251121\n",
      "0.8116591928251121\n",
      "21 10 269 0.8116591928251121\n",
      "0.8116591928251121\n",
      "21 11 270 0.8116591928251121\n",
      "0.8116591928251121\n",
      "21 12 271 0.8116591928251121\n",
      "0.8116591928251121\n",
      "21 13 272 0.8116591928251121\n",
      "0.8116591928251121\n",
      "21 14 273 0.8116591928251121\n",
      "0.8116591928251121\n",
      "22 2 274 0.7847533632286996\n",
      "22 3 275 0.820627802690583\n",
      "22 4 276 0.820627802690583\n",
      "0.820627802690583\n",
      "22 5 277 0.8071748878923767\n",
      "0.8071748878923767\n",
      "22 6 278 0.8116591928251121\n",
      "0.8116591928251121\n",
      "22 7 279 0.8116591928251121\n",
      "0.8116591928251121\n",
      "22 8 280 0.8116591928251121\n",
      "0.8116591928251121\n",
      "22 9 281 0.8116591928251121\n",
      "0.8116591928251121\n",
      "22 10 282 0.8116591928251121\n",
      "0.8116591928251121\n",
      "22 11 283 0.8116591928251121\n",
      "0.8116591928251121\n",
      "22 12 284 0.8116591928251121\n",
      "0.8116591928251121\n",
      "22 13 285 0.8116591928251121\n",
      "0.8116591928251121\n",
      "22 14 286 0.8116591928251121\n",
      "0.8116591928251121\n",
      "23 2 287 0.7847533632286996\n",
      "23 3 288 0.820627802690583\n",
      "23 4 289 0.820627802690583\n",
      "0.820627802690583\n",
      "23 5 290 0.8071748878923767\n",
      "0.8071748878923767\n",
      "23 6 291 0.8116591928251121\n",
      "0.8116591928251121\n",
      "23 7 292 0.8116591928251121\n",
      "0.8116591928251121\n",
      "23 8 293 0.8116591928251121\n",
      "0.8116591928251121\n",
      "23 9 294 0.8116591928251121\n",
      "0.8116591928251121\n",
      "23 10 295 0.8116591928251121\n",
      "0.8116591928251121\n",
      "23 11 296 0.8116591928251121\n",
      "0.8116591928251121\n",
      "23 12 297 0.8116591928251121\n",
      "0.8116591928251121\n",
      "23 13 298 0.8116591928251121\n",
      "0.8116591928251121\n",
      "23 14 299 0.8116591928251121\n",
      "0.8116591928251121\n",
      "24 2 300 0.7847533632286996\n",
      "24 3 301 0.820627802690583\n",
      "24 4 302 0.820627802690583\n",
      "0.820627802690583\n",
      "24 5 303 0.8071748878923767\n",
      "0.8071748878923767\n",
      "24 6 304 0.8116591928251121\n",
      "0.8116591928251121\n",
      "24 7 305 0.8116591928251121\n",
      "0.8116591928251121\n",
      "24 8 306 0.8116591928251121\n",
      "0.8116591928251121\n",
      "24 9 307 0.8116591928251121\n",
      "0.8116591928251121\n",
      "24 10 308 0.8116591928251121\n",
      "0.8116591928251121\n",
      "24 11 309 0.8116591928251121\n",
      "0.8116591928251121\n",
      "24 12 310 0.8116591928251121\n",
      "0.8116591928251121\n",
      "24 13 311 0.8116591928251121\n",
      "0.8116591928251121\n",
      "24 14 312 0.8116591928251121\n",
      "0.8116591928251121\n",
      "25 2 313 0.7847533632286996\n",
      "25 3 314 0.820627802690583\n",
      "25 4 315 0.820627802690583\n",
      "0.820627802690583\n",
      "25 5 316 0.8071748878923767\n",
      "0.8071748878923767\n",
      "25 6 317 0.8116591928251121\n",
      "0.8116591928251121\n",
      "25 7 318 0.8116591928251121\n",
      "0.8116591928251121\n",
      "25 8 319 0.8116591928251121\n",
      "0.8116591928251121\n",
      "25 9 320 0.8116591928251121\n",
      "0.8116591928251121\n",
      "25 10 321 0.8116591928251121\n",
      "0.8116591928251121\n",
      "25 11 322 0.8116591928251121\n",
      "0.8116591928251121\n",
      "25 12 323 0.8116591928251121\n",
      "0.8116591928251121\n",
      "25 13 324 0.8116591928251121\n",
      "0.8116591928251121\n",
      "25 14 325 0.8116591928251121\n",
      "0.8116591928251121\n",
      "26 2 326 0.7847533632286996\n",
      "26 3 327 0.820627802690583\n",
      "26 4 328 0.820627802690583\n",
      "0.820627802690583\n",
      "26 5 329 0.8071748878923767\n",
      "0.8071748878923767\n",
      "26 6 330 0.8116591928251121\n",
      "0.8116591928251121\n",
      "26 7 331 0.8116591928251121\n",
      "0.8116591928251121\n",
      "26 8 332 0.8116591928251121\n",
      "0.8116591928251121\n",
      "26 9 333 0.8116591928251121\n",
      "0.8116591928251121\n",
      "26 10 334 0.8116591928251121\n",
      "0.8116591928251121\n",
      "26 11 335 0.8116591928251121\n",
      "0.8116591928251121\n",
      "26 12 336 0.8116591928251121\n",
      "0.8116591928251121\n",
      "26 13 337 0.8116591928251121\n",
      "0.8116591928251121\n",
      "26 14 338 0.8116591928251121\n",
      "0.8116591928251121\n",
      "27 2 339 0.7847533632286996\n",
      "27 3 340 0.820627802690583\n",
      "27 4 341 0.820627802690583\n",
      "0.820627802690583\n",
      "27 5 342 0.8116591928251121\n",
      "0.8116591928251121\n",
      "27 6 343 0.8116591928251121\n",
      "0.8116591928251121\n",
      "27 7 344 0.8116591928251121\n",
      "0.8116591928251121\n",
      "27 8 345 0.8116591928251121\n",
      "0.8116591928251121\n",
      "27 9 346 0.8116591928251121\n",
      "0.8116591928251121\n",
      "27 10 347 0.8116591928251121\n",
      "0.8116591928251121\n",
      "27 11 348 0.8116591928251121\n",
      "0.8116591928251121\n",
      "27 12 349 0.8116591928251121\n",
      "0.8116591928251121\n",
      "27 13 350 0.8116591928251121\n",
      "0.8116591928251121\n",
      "27 14 351 0.8116591928251121\n",
      "0.8116591928251121\n",
      "28 2 352 0.7847533632286996\n",
      "28 3 353 0.820627802690583\n",
      "28 4 354 0.820627802690583\n",
      "0.820627802690583\n",
      "28 5 355 0.8116591928251121\n",
      "0.8116591928251121\n",
      "28 6 356 0.8116591928251121\n",
      "0.8116591928251121\n",
      "28 7 357 0.8116591928251121\n",
      "0.8116591928251121\n",
      "28 8 358 0.8116591928251121\n",
      "0.8116591928251121\n",
      "28 9 359 0.8116591928251121\n",
      "0.8116591928251121\n",
      "28 10 360 0.8116591928251121\n",
      "0.8116591928251121\n",
      "28 11 361 0.8116591928251121\n",
      "0.8116591928251121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 12 362 0.8116591928251121\n",
      "0.8116591928251121\n",
      "28 13 363 0.8116591928251121\n",
      "0.8116591928251121\n",
      "28 14 364 0.8116591928251121\n",
      "0.8116591928251121\n",
      "29 2 365 0.7847533632286996\n",
      "29 3 366 0.820627802690583\n",
      "29 4 367 0.820627802690583\n",
      "0.820627802690583\n",
      "29 5 368 0.8116591928251121\n",
      "0.8116591928251121\n",
      "29 6 369 0.8116591928251121\n",
      "0.8116591928251121\n",
      "29 7 370 0.8116591928251121\n",
      "0.8116591928251121\n",
      "29 8 371 0.8116591928251121\n",
      "0.8116591928251121\n",
      "29 9 372 0.8116591928251121\n",
      "0.8116591928251121\n",
      "29 10 373 0.8116591928251121\n",
      "0.8116591928251121\n",
      "29 11 374 0.8116591928251121\n",
      "0.8116591928251121\n",
      "29 12 375 0.8116591928251121\n",
      "0.8116591928251121\n",
      "29 13 376 0.8116591928251121\n",
      "0.8116591928251121\n",
      "29 14 377 0.8116591928251121\n",
      "0.8116591928251121\n",
      "30 2 378 0.7847533632286996\n",
      "30 3 379 0.820627802690583\n",
      "30 4 380 0.820627802690583\n",
      "0.820627802690583\n",
      "30 5 381 0.8116591928251121\n",
      "0.8116591928251121\n",
      "30 6 382 0.8116591928251121\n",
      "0.8116591928251121\n",
      "30 7 383 0.8116591928251121\n",
      "0.8116591928251121\n",
      "30 8 384 0.8116591928251121\n",
      "0.8116591928251121\n",
      "30 9 385 0.8116591928251121\n",
      "0.8116591928251121\n",
      "30 10 386 0.8116591928251121\n",
      "0.8116591928251121\n",
      "30 11 387 0.8116591928251121\n",
      "0.8116591928251121\n",
      "30 12 388 0.8116591928251121\n",
      "0.8116591928251121\n",
      "30 13 389 0.8116591928251121\n",
      "0.8116591928251121\n",
      "30 14 390 0.8116591928251121\n",
      "0.8116591928251121\n",
      "31 2 391 0.7847533632286996\n",
      "31 3 392 0.820627802690583\n",
      "31 4 393 0.820627802690583\n",
      "0.820627802690583\n",
      "31 5 394 0.8116591928251121\n",
      "0.8116591928251121\n",
      "31 6 395 0.8116591928251121\n",
      "0.8116591928251121\n",
      "31 7 396 0.8116591928251121\n",
      "0.8116591928251121\n",
      "31 8 397 0.8116591928251121\n",
      "0.8116591928251121\n",
      "31 9 398 0.8116591928251121\n",
      "0.8116591928251121\n",
      "31 10 399 0.8116591928251121\n",
      "0.8116591928251121\n",
      "31 11 400 0.8116591928251121\n",
      "0.8116591928251121\n",
      "31 12 401 0.8116591928251121\n",
      "0.8116591928251121\n",
      "31 13 402 0.8116591928251121\n",
      "0.8116591928251121\n",
      "31 14 403 0.8116591928251121\n",
      "0.8116591928251121\n",
      "32 2 404 0.7847533632286996\n",
      "32 3 405 0.8251121076233184\n",
      "---------------------------> 0.8251121076233184 0.820627802690583 RandomForestClassifier(criterion='entropy', max_depth=4, max_features='log2',\n",
      "                       n_estimators=20, n_jobs=-1, random_state=42)\n",
      "32 4 406 0.820627802690583\n",
      "0.820627802690583\n",
      "32 5 407 0.8116591928251121\n",
      "0.8116591928251121\n",
      "32 6 408 0.8116591928251121\n",
      "0.8116591928251121\n",
      "32 7 409 0.8116591928251121\n",
      "0.8116591928251121\n",
      "32 8 410 0.8116591928251121\n",
      "0.8116591928251121\n",
      "32 9 411 0.8116591928251121\n",
      "0.8116591928251121\n",
      "32 10 412 0.8116591928251121\n",
      "0.8116591928251121\n",
      "32 11 413 0.8116591928251121\n",
      "0.8116591928251121\n",
      "32 12 414 0.8116591928251121\n",
      "0.8116591928251121\n",
      "32 13 415 0.8116591928251121\n",
      "0.8116591928251121\n",
      "32 14 416 0.8116591928251121\n",
      "0.8116591928251121\n",
      "33 2 417 0.7847533632286996\n",
      "33 3 418 0.8251121076233184\n",
      "33 4 419 0.820627802690583\n",
      "0.820627802690583\n",
      "33 5 420 0.8116591928251121\n",
      "0.8116591928251121\n",
      "33 6 421 0.8116591928251121\n",
      "0.8116591928251121\n",
      "33 7 422 0.8116591928251121\n",
      "0.8116591928251121\n",
      "33 8 423 0.8116591928251121\n",
      "0.8116591928251121\n",
      "33 9 424 0.8116591928251121\n",
      "0.8116591928251121\n",
      "33 10 425 0.8116591928251121\n",
      "0.8116591928251121\n",
      "33 11 426 0.8116591928251121\n",
      "0.8116591928251121\n",
      "33 12 427 0.8116591928251121\n",
      "0.8116591928251121\n",
      "33 13 428 0.8116591928251121\n",
      "0.8116591928251121\n",
      "33 14 429 0.8116591928251121\n",
      "0.8116591928251121\n",
      "34 2 430 0.7847533632286996\n",
      "34 3 431 0.8251121076233184\n",
      "34 4 432 0.820627802690583\n",
      "0.820627802690583\n",
      "34 5 433 0.8116591928251121\n",
      "0.8116591928251121\n",
      "34 6 434 0.8116591928251121\n",
      "0.8116591928251121\n",
      "34 7 435 0.8116591928251121\n",
      "0.8116591928251121\n",
      "34 8 436 0.8116591928251121\n",
      "0.8116591928251121\n",
      "34 9 437 0.8116591928251121\n",
      "0.8116591928251121\n",
      "34 10 438 0.8116591928251121\n",
      "0.8116591928251121\n",
      "34 11 439 0.8116591928251121\n",
      "0.8116591928251121\n",
      "34 12 440 0.8116591928251121\n",
      "0.8116591928251121\n",
      "34 13 441 0.8116591928251121\n",
      "0.8116591928251121\n",
      "34 14 442 0.8116591928251121\n",
      "0.8116591928251121\n",
      "35 2 443 0.7847533632286996\n",
      "35 3 444 0.8251121076233184\n",
      "35 4 445 0.820627802690583\n",
      "0.820627802690583\n",
      "35 5 446 0.8116591928251121\n",
      "0.8116591928251121\n",
      "35 6 447 0.8116591928251121\n",
      "0.8116591928251121\n",
      "35 7 448 0.8116591928251121\n",
      "0.8116591928251121\n",
      "35 8 449 0.8116591928251121\n",
      "0.8116591928251121\n",
      "35 9 450 0.8116591928251121\n",
      "0.8116591928251121\n",
      "35 10 451 0.8116591928251121\n",
      "0.8116591928251121\n",
      "35 11 452 0.8116591928251121\n",
      "0.8116591928251121\n",
      "35 12 453 0.8116591928251121\n",
      "0.8116591928251121\n",
      "35 13 454 0.8116591928251121\n",
      "0.8116591928251121\n",
      "35 14 455 0.8116591928251121\n",
      "0.8116591928251121\n",
      "36 2 456 0.7847533632286996\n",
      "36 3 457 0.8251121076233184\n",
      "36 4 458 0.820627802690583\n",
      "0.820627802690583\n",
      "36 5 459 0.8116591928251121\n",
      "0.8116591928251121\n",
      "36 6 460 0.8116591928251121\n",
      "0.8116591928251121\n",
      "36 7 461 0.8116591928251121\n",
      "0.8116591928251121\n",
      "36 8 462 0.8116591928251121\n",
      "0.8116591928251121\n",
      "36 9 463 0.8116591928251121\n",
      "0.8116591928251121\n",
      "36 10 464 0.8116591928251121\n",
      "0.8116591928251121\n",
      "36 11 465 0.8116591928251121\n",
      "0.8116591928251121\n",
      "36 12 466 0.8116591928251121\n",
      "0.8116591928251121\n",
      "36 13 467 0.8116591928251121\n",
      "0.8116591928251121\n",
      "36 14 468 0.8116591928251121\n",
      "0.8116591928251121\n",
      "37 2 469 0.7847533632286996\n",
      "37 3 470 0.8251121076233184\n",
      "37 4 471 0.820627802690583\n",
      "0.820627802690583\n",
      "37 5 472 0.8116591928251121\n",
      "0.8116591928251121\n",
      "37 6 473 0.8116591928251121\n",
      "0.8116591928251121\n",
      "37 7 474 0.8116591928251121\n",
      "0.8116591928251121\n",
      "37 8 475 0.8116591928251121\n",
      "0.8116591928251121\n",
      "37 9 476 0.8116591928251121\n",
      "0.8116591928251121\n",
      "37 10 477 0.8116591928251121\n",
      "0.8116591928251121\n",
      "37 11 478 0.8116591928251121\n",
      "0.8116591928251121\n",
      "37 12 479 0.8116591928251121\n",
      "0.8116591928251121\n",
      "37 13 480 0.8116591928251121\n",
      "0.8116591928251121\n",
      "37 14 481 0.8116591928251121\n",
      "0.8116591928251121\n",
      "38 2 482 0.7847533632286996\n",
      "38 3 483 0.8251121076233184\n",
      "38 4 484 0.820627802690583\n",
      "0.820627802690583\n",
      "38 5 485 0.8116591928251121\n",
      "0.8116591928251121\n",
      "38 6 486 0.8116591928251121\n",
      "0.8116591928251121\n",
      "38 7 487 0.8116591928251121\n",
      "0.8116591928251121\n",
      "38 8 488 0.8116591928251121\n",
      "0.8116591928251121\n",
      "38 9 489 0.8116591928251121\n",
      "0.8116591928251121\n",
      "38 10 490 0.8116591928251121\n",
      "0.8116591928251121\n",
      "38 11 491 0.8116591928251121\n",
      "0.8116591928251121\n",
      "38 12 492 0.8116591928251121\n",
      "0.8116591928251121\n",
      "38 13 493 0.8116591928251121\n",
      "0.8116591928251121\n",
      "38 14 494 0.8116591928251121\n",
      "0.8116591928251121\n",
      "39 2 495 0.7847533632286996\n",
      "39 3 496 0.8251121076233184\n",
      "39 4 497 0.820627802690583\n",
      "0.820627802690583\n",
      "39 5 498 0.8116591928251121\n",
      "0.8116591928251121\n",
      "39 6 499 0.8116591928251121\n",
      "0.8116591928251121\n",
      "39 7 500 0.8116591928251121\n",
      "0.8116591928251121\n",
      "39 8 501 0.8116591928251121\n",
      "0.8116591928251121\n",
      "39 9 502 0.8116591928251121\n",
      "0.8116591928251121\n",
      "39 10 503 0.8116591928251121\n",
      "0.8116591928251121\n",
      "39 11 504 0.8116591928251121\n",
      "0.8116591928251121\n",
      "39 12 505 0.8116591928251121\n",
      "0.8116591928251121\n",
      "39 13 506 0.8116591928251121\n",
      "0.8116591928251121\n",
      "39 14 507 0.8116591928251121\n",
      "0.8116591928251121\n",
      "40 2 508 0.7847533632286996\n",
      "40 3 509 0.8251121076233184\n",
      "40 4 510 0.820627802690583\n",
      "0.820627802690583\n",
      "40 5 511 0.8116591928251121\n",
      "0.8116591928251121\n",
      "40 6 512 0.8116591928251121\n",
      "0.8116591928251121\n",
      "40 7 513 0.8116591928251121\n",
      "0.8116591928251121\n",
      "40 8 514 0.8116591928251121\n",
      "0.8116591928251121\n",
      "40 9 515 0.8116591928251121\n",
      "0.8116591928251121\n",
      "40 10 516 0.8116591928251121\n",
      "0.8116591928251121\n",
      "40 11 517 0.8116591928251121\n",
      "0.8116591928251121\n",
      "40 12 518 0.8116591928251121\n",
      "0.8116591928251121\n",
      "40 13 519 0.8116591928251121\n",
      "0.8116591928251121\n",
      "40 14 520 0.8116591928251121\n",
      "0.8116591928251121\n",
      "41 2 521 0.7847533632286996\n",
      "41 3 522 0.8251121076233184\n",
      "41 4 523 0.820627802690583\n",
      "0.820627802690583\n",
      "41 5 524 0.8116591928251121\n",
      "0.8116591928251121\n",
      "41 6 525 0.8116591928251121\n",
      "0.8116591928251121\n",
      "41 7 526 0.8116591928251121\n",
      "0.8116591928251121\n",
      "41 8 527 0.8116591928251121\n",
      "0.8116591928251121\n",
      "41 9 528 0.8116591928251121\n",
      "0.8116591928251121\n",
      "41 10 529 0.8116591928251121\n",
      "0.8116591928251121\n",
      "41 11 530 0.8116591928251121\n",
      "0.8116591928251121\n",
      "41 12 531 0.8116591928251121\n",
      "0.8116591928251121\n",
      "41 13 532 0.8116591928251121\n",
      "0.8116591928251121\n",
      "41 14 533 0.8116591928251121\n",
      "0.8116591928251121\n",
      "42 2 534 0.7847533632286996\n",
      "42 3 535 0.8251121076233184\n",
      "42 4 536 0.820627802690583\n",
      "0.820627802690583\n",
      "42 5 537 0.8116591928251121\n",
      "0.8116591928251121\n",
      "42 6 538 0.8116591928251121\n",
      "0.8116591928251121\n",
      "42 7 539 0.8116591928251121\n",
      "0.8116591928251121\n",
      "42 8 540 0.8116591928251121\n",
      "0.8116591928251121\n",
      "42 9 541 0.8116591928251121\n",
      "0.8116591928251121\n",
      "42 10 542 0.8116591928251121\n",
      "0.8116591928251121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 11 543 0.8116591928251121\n",
      "0.8116591928251121\n",
      "42 12 544 0.8116591928251121\n",
      "0.8116591928251121\n",
      "42 13 545 0.8116591928251121\n",
      "0.8116591928251121\n",
      "42 14 546 0.8116591928251121\n",
      "0.8116591928251121\n",
      "43 2 547 0.7847533632286996\n",
      "43 3 548 0.8251121076233184\n",
      "43 4 549 0.820627802690583\n",
      "0.820627802690583\n",
      "43 5 550 0.8116591928251121\n",
      "0.8116591928251121\n",
      "43 6 551 0.8116591928251121\n",
      "0.8116591928251121\n",
      "43 7 552 0.8116591928251121\n",
      "0.8116591928251121\n",
      "43 8 553 0.8116591928251121\n",
      "0.8116591928251121\n",
      "43 9 554 0.8116591928251121\n",
      "0.8116591928251121\n",
      "43 10 555 0.8116591928251121\n",
      "0.8116591928251121\n",
      "43 11 556 0.8116591928251121\n",
      "0.8116591928251121\n",
      "43 12 557 0.8116591928251121\n",
      "0.8116591928251121\n",
      "43 13 558 0.8116591928251121\n",
      "0.8116591928251121\n",
      "43 14 559 0.8116591928251121\n",
      "0.8116591928251121\n",
      "44 2 560 0.7847533632286996\n",
      "44 3 561 0.8251121076233184\n",
      "44 4 562 0.820627802690583\n",
      "0.820627802690583\n",
      "44 5 563 0.8116591928251121\n",
      "0.8116591928251121\n",
      "44 6 564 0.8116591928251121\n",
      "0.8116591928251121\n",
      "44 7 565 0.8116591928251121\n",
      "0.8116591928251121\n",
      "44 8 566 0.8116591928251121\n",
      "0.8116591928251121\n",
      "44 9 567 0.8116591928251121\n",
      "0.8116591928251121\n",
      "44 10 568 0.8116591928251121\n",
      "0.8116591928251121\n",
      "44 11 569 0.8116591928251121\n",
      "0.8116591928251121\n",
      "44 12 570 0.8116591928251121\n",
      "0.8116591928251121\n",
      "44 13 571 0.8116591928251121\n",
      "0.8116591928251121\n",
      "44 14 572 0.8116591928251121\n",
      "0.8116591928251121\n",
      "45 2 573 0.7847533632286996\n",
      "45 3 574 0.8251121076233184\n",
      "45 4 575 0.820627802690583\n",
      "0.820627802690583\n",
      "45 5 576 0.8116591928251121\n",
      "0.8116591928251121\n",
      "45 6 577 0.8116591928251121\n",
      "0.8116591928251121\n",
      "45 7 578 0.8116591928251121\n",
      "0.8116591928251121\n",
      "45 8 579 0.8116591928251121\n",
      "0.8116591928251121\n",
      "45 9 580 0.8116591928251121\n",
      "0.8116591928251121\n",
      "45 10 581 0.8116591928251121\n",
      "0.8116591928251121\n",
      "45 11 582 0.8116591928251121\n",
      "0.8116591928251121\n",
      "45 12 583 0.8116591928251121\n",
      "0.8116591928251121\n",
      "45 13 584 0.8116591928251121\n",
      "0.8116591928251121\n",
      "45 14 585 0.8116591928251121\n",
      "0.8116591928251121\n",
      "46 2 586 0.7847533632286996\n",
      "46 3 587 0.8251121076233184\n",
      "46 4 588 0.820627802690583\n",
      "0.820627802690583\n",
      "46 5 589 0.8116591928251121\n",
      "0.8116591928251121\n",
      "46 6 590 0.8116591928251121\n",
      "0.8116591928251121\n",
      "46 7 591 0.8116591928251121\n",
      "0.8116591928251121\n",
      "46 8 592 0.8116591928251121\n",
      "0.8116591928251121\n",
      "46 9 593 0.8116591928251121\n",
      "0.8116591928251121\n",
      "46 10 594 0.8116591928251121\n",
      "0.8116591928251121\n",
      "46 11 595 0.8116591928251121\n",
      "0.8116591928251121\n",
      "46 12 596 0.8116591928251121\n",
      "0.8116591928251121\n",
      "46 13 597 0.8116591928251121\n",
      "0.8116591928251121\n",
      "46 14 598 0.8116591928251121\n",
      "0.8116591928251121\n",
      "47 2 599 0.7847533632286996\n",
      "47 3 600 0.8251121076233184\n",
      "47 4 601 0.820627802690583\n",
      "0.820627802690583\n",
      "47 5 602 0.8116591928251121\n",
      "0.8116591928251121\n",
      "47 6 603 0.8116591928251121\n",
      "0.8116591928251121\n",
      "47 7 604 0.8116591928251121\n",
      "0.8116591928251121\n",
      "47 8 605 0.8116591928251121\n",
      "0.8116591928251121\n",
      "47 9 606 0.8116591928251121\n",
      "0.8116591928251121\n",
      "47 10 607 0.8116591928251121\n",
      "0.8116591928251121\n",
      "47 11 608 0.8116591928251121\n",
      "0.8116591928251121\n",
      "47 12 609 0.8116591928251121\n",
      "0.8116591928251121\n",
      "47 13 610 0.8116591928251121\n",
      "0.8116591928251121\n",
      "47 14 611 0.8116591928251121\n",
      "0.8116591928251121\n",
      "48 2 612 0.7847533632286996\n",
      "48 3 613 0.820627802690583\n",
      "48 4 614 0.820627802690583\n",
      "0.820627802690583\n",
      "48 5 615 0.8116591928251121\n",
      "0.8116591928251121\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1036-cedb538225c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"entropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"log2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m    388\u001b[0m                              \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'threads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sklearn_score = dummy_accuracy\n",
    "clf_best = 0\n",
    "it = 0\n",
    "for i in range(1, 200):\n",
    "    score = 0\n",
    "    for j in range(2, 15):\n",
    "        for k in range(2, 3):\n",
    "            clf = RandomForestClassifier(criterion=\"entropy\", max_features=\"log2\", n_estimators=i*10, max_depth=j, random_state=42, n_jobs=-1)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            accuracy = clf.score(X_test, y_test)\n",
    "            it += 1\n",
    "            print(i, j, it, accuracy)\n",
    "            if accuracy > sklearn_score:\n",
    "                print(\"--------------------------->\", accuracy, sklearn_score, clf_best)\n",
    "                sklearn_score = accuracy\n",
    "                clf_best = clf\n",
    "            elif accuracy <= score:\n",
    "                print(accuracy)\n",
    "                break\n",
    "            score = accuracy\n",
    "            \n",
    "        \n",
    "print(sklearn_score, clf_best, it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the data split indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1387,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "def shuffle():\n",
    "    s = ShuffleSplit(n_splits=1000, random_state=42)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the indices to create dictionaries of train/test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subsets(s):\n",
    "    X_subsets = {}\n",
    "    y_subsets = {}\n",
    "\n",
    "    for i, indexes in enumerate(s.split(X_train)):\n",
    "        X_subsets[i] = X_train.values[indexes[0], :]\n",
    "        y_subsets[i] = y_train.values[indexes[0]]\n",
    "    \n",
    "    return X_subsets, y_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1389,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Growing the Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grow_forest():\n",
    "    forest = []\n",
    "    ypreds = []\n",
    "    scores = []\n",
    "    # Defining the decision tree model\n",
    "    clf = DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features='log2',\n",
    "                       random_state=42)\n",
    "\n",
    "    # Growing the forest\n",
    "    \n",
    "    s = shuffle()\n",
    "    X_subsets, y_subsets = create_subsets(s)\n",
    "    \n",
    "    for subset in range(s.get_n_splits()):\n",
    "        tree = clf.fit(X_subsets[subset], y_subsets[subset])    \n",
    "        forest.append(tree)\n",
    "    \n",
    "        ypred = clf.predict(X_test.values)\n",
    "        ypreds.append(ypred)\n",
    "    \n",
    "        scores.append(clf.score(X_test, y_test))\n",
    "        \n",
    "        ## Creating a confusion matrix and a plot for each tree ##\n",
    "        # plot_confusion_matrix(clf, X_test, y_test, cmap=plt.cm.Blues)\n",
    "        # plt.savefig(f\"plots/conf_matr{subset}.jpg\")\n",
    "        # plt.close()\n",
    "        # plt.figure(figsize=(12, 8), dpi=150)\n",
    "        # plot_tree(clf, feature_names=X.columns, class_names=[\"survived\", \"drowned\"], filled=True)\n",
    "        # plt.savefig(f\"plots/tree{subset}.jpg\")\n",
    "        # plt.close()\n",
    "        \n",
    "    return forest, ypreds, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1391,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest, ypreds, scores = grow_forest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1392,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "images = []\n",
    "\n",
    "for i in range(200):\n",
    "    filename = f'plots/tree{i}.jpg'.format(i)\n",
    "    images.append(imageio.imread(filename))\n",
    "\n",
    "imageio.mimsave('trees.gif', images, fps=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1393,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for i in range(200):\n",
    "    filename = f'plots/conf_matr{i}.jpg'.format(i)\n",
    "    images.append(imageio.imread(filename))\n",
    "\n",
    "imageio.mimsave('conf_matr.gif', images, fps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority Vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>302</th>\n",
       "      <th>303</th>\n",
       "      <th>304</th>\n",
       "      <th>305</th>\n",
       "      <th>306</th>\n",
       "      <th>307</th>\n",
       "      <th>308</th>\n",
       "      <th>309</th>\n",
       "      <th>310</th>\n",
       "      <th>311</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  302  303  304  305  \\\n",
       "0    1    0    0    1    1    1    1    0    1    1  ...    0    0    0    1   \n",
       "1    1    0    0    1    1    1    1    0    1    1  ...    0    0    0    0   \n",
       "2    1    0    0    1    1    1    1    0    1    1  ...    0    0    0    0   \n",
       "3    1    0    0    1    1    1    1    0    1    1  ...    0    0    0    0   \n",
       "4    1    0    0    1    1    1    1    0    1    1  ...    0    0    0    0   \n",
       "\n",
       "   306  307  308  309  310  311  \n",
       "0    0    1    1    0    1    1  \n",
       "1    0    1    1    0    0    1  \n",
       "2    0    1    1    0    0    1  \n",
       "3    0    1    1    0    0    1  \n",
       "4    0    1    1    0    0    1  \n",
       "\n",
       "[5 rows x 312 columns]"
      ]
     },
     "execution_count": 1396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ballots = pd.DataFrame(ypreds)\n",
    "ballots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1397,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreboard = pd.DataFrame(data=ypreds)\n",
    "scoreboard = pd.concat([scoreboard, pd.Series(scores, name=\"score\")], axis=1)\n",
    "best_score_index = scoreboard[scoreboard[\"score\"] == scoreboard[\"score\"].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>302</th>\n",
       "      <th>303</th>\n",
       "      <th>304</th>\n",
       "      <th>305</th>\n",
       "      <th>306</th>\n",
       "      <th>307</th>\n",
       "      <th>308</th>\n",
       "      <th>309</th>\n",
       "      <th>310</th>\n",
       "      <th>311</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  302  303  304  305  \\\n",
       "0    1    0    0    1    1    1    1    0    1    1  ...    0    0    0    0   \n",
       "\n",
       "   306  307  308  309  310  311  \n",
       "0    0    1    1    0    0    1  \n",
       "\n",
       "[1 rows x 312 columns]"
      ]
     },
     "execution_count": 1398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ballots.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    1\n",
       "1    0\n",
       "2    0\n",
       "3    1\n",
       "4    1\n",
       "..  ..\n",
       "307  1\n",
       "308  1\n",
       "309  0\n",
       "310  0\n",
       "311  1\n",
       "\n",
       "[312 rows x 1 columns]"
      ]
     },
     "execution_count": 1399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote = ballots.mode().transpose()\n",
    "vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of the vote 0.824\n",
      "sklearn_score 0.827\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(vote, y_test)\n",
    "print(\"Accuracy Score of the vote\", round(accuracy, 3))\n",
    "print(\"sklearn_score\", round(sklearn_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median Score and Maximum Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median score: 0.817\n",
      "Maximum score 0.833\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(\"Median score:\",round(statistics.median(scores), 3))\n",
    "print(\"Maximum score\",round(max(scores), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[162,  26],\n",
       "       [ 29,  95]])"
      ]
     },
     "execution_count": 1402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_test, vote)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Confusion Matrix')"
      ]
     },
     "execution_count": 1403,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion, cmap=\"mako\", annot=True, fmt='g')\n",
    "plt.xlabel(\"Predicted\", fontsize=14)\n",
    "plt.ylabel(\"True\", fontsize=14)\n",
    "plt.title(\"Confusion Matrix\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Cross-validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1404,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "\n",
    "def shuffle(n):\n",
    "    s = ShuffleSplit(n_splits=n, random_state=42)\n",
    "    return s\n",
    "\n",
    "def create_subsets(s, X, y):\n",
    "    X_subsets = {}\n",
    "    y_subsets = {}\n",
    "    for i, indices in enumerate(s.split(X)):\n",
    "        X_subsets[i] = X.values[indices[0], :]\n",
    "        y_subsets[i] = y.values[indices[0]]\n",
    "   \n",
    "    return [X_subsets, y_subsets]\n",
    "        \n",
    "\n",
    "def grow_forest(s, X_subsets, y_subsets, X_test, y_test):\n",
    "    forest = []\n",
    "    ypreds = []\n",
    "    scores = []\n",
    "    # Defining the decision tree model\n",
    "    clf = DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features='log2', random_state=42)\n",
    "\n",
    "    # Growing the forest\n",
    "    for subset in range(s.get_n_splits()):\n",
    "        tree = clf.fit(X_subsets[subset], y_subsets[subset])    \n",
    "        forest.append(tree)\n",
    "    \n",
    "        ypred = clf.predict(X_test.values)\n",
    "        ypreds.append(ypred)\n",
    "    \n",
    "        scores.append(clf.score(X_test, y_test))\n",
    "    \n",
    "        ## Creating a plot for each tree ##\n",
    "    \n",
    "        # plt.figure(figsize=(12, 8), dpi=150)\n",
    "        # plot_tree(clf, feature_names=X.columns, class_names=[\"survived\", \"drowned\"], filled=True)\n",
    "        # plt.savefig(f\"plots/tree{i}.jpg\")\n",
    "        # plt.close()\n",
    "    return forest, ypreds, scores\n",
    "\n",
    "def random_forest(X, y, X_test, y_test):\n",
    "    s = shuffle(n=1000)\n",
    "    X_subsets, y_subsets = create_subsets(s, X, y)\n",
    "    forest, ypreds, scores = grow_forest(s, X_subsets, y_subsets, X_test, y_test)\n",
    "    return forest, ypreds, scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "961\n",
      "0.8156424581005587\n",
      "0.8089887640449438\n",
      "50\n",
      "0.8426966292134831\n",
      "0.7865168539325843\n",
      "0.8258426966292135\n",
      "0.8044692737430168\n",
      "0.8258426966292135\n",
      "0.8202247191011236\n",
      "0.8146067415730337\n",
      "0.8089887640449438\n",
      "0.8156424581005587\n",
      "0.8089887640449438\n",
      "0.8089887640449438\n",
      "0.8089887640449438\n",
      "0.8146067415730337\n",
      "710\n",
      "0.88268156424581\n",
      "0.7696629213483146\n",
      "0.8258426966292135\n",
      "0.8089887640449438\n",
      "0.8033707865168539\n",
      "0.8324022346368715\n",
      "0.8370786516853933\n",
      "0.8033707865168539\n",
      "0.8089887640449438\n",
      "0.7921348314606742\n",
      "0.8089887640449438\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import statistics\n",
    "\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
    "# print(rkf.split(df))\n",
    "\n",
    "X_train_subsets = {}\n",
    "y_train_subsets = {}\n",
    "X_test_subsets = {}\n",
    "y_test_subsets = {}\n",
    "\n",
    "accuracies = []\n",
    "for index, train_test in enumerate(rkf.split(df)):\n",
    "    X_train_subsets[index] = df[[\"rank\", \"Sex_male\", \"SibSp\", \"cabin_number\"]].values[train_test[0], :]\n",
    "    X_test_subsets[index] = df[[\"rank\", \"Sex_male\", \"SibSp\", \"cabin_number\"]].values[train_test[1], :]\n",
    "    y_train_subsets[index] = df[\"Survived\"].values[train_test[0]]\n",
    "    y_test_subsets[index] = df[\"Survived\"].values[train_test[1]]\n",
    "\n",
    "high_score = dummy_accuracy\n",
    "high_list = []\n",
    "for subset in range(rkf.get_n_splits()):\n",
    "    forest, ypreds, scores = random_forest(pd.DataFrame(X_train_subsets[subset]), pd.Series(y_train_subsets[subset]), pd.DataFrame(X_test_subsets[subset]), pd.Series(y_test_subsets[subset]))\n",
    "    \n",
    "    if max(scores) > high_score:\n",
    "        high_score = max(scores)\n",
    "        print((scores.index(max(scores))))\n",
    "        high_list = [forest[scores.index(max(scores))],\n",
    "                     ypreds[scores.index(max(scores))],\n",
    "                     high_score]\n",
    "\n",
    "    ballots = pd.DataFrame(ypreds)\n",
    "    vote = ballots.mode().transpose()\n",
    "    accuracy = accuracy_score(vote[0].values.astype(int), y_test_subsets[subset])\n",
    "    accuracies.append(accuracy)\n",
    "    print(accuracy)\n",
    "\n",
    "print(statistics.median(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features='log2',\n",
      "                       random_state=42), array([1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
      "       1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
      "       0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "       1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "       1, 1, 1]), 0.8994413407821229]\n"
     ]
    }
   ],
   "source": [
    "print(high_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8301282051282052"
      ]
     },
     "execution_count": 1448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(penalty='l2', C=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 1431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(criterion=\"entropy\", n_estimators=1000, max_features='log2', max_depth=9, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1456,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8525641025641025"
      ]
     },
     "execution_count": 1456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "models = [('logreg', LogisticRegression(penalty='l2', C=10, max_iter=100, random_state=42)),\n",
    "          (\"forest\", RandomForestClassifier(criterion=\"entropy\", max_features='log2', n_estimators=1000, max_depth=9, random_state=42)),\n",
    "          ('svm', SVC(kernel='rbf', probability=False, random_state=42)),\n",
    "          ]\n",
    "m = VotingClassifier(models, n_jobs=-1, voting=\"hard\")\n",
    "\n",
    "m.fit(X_train, y_train)\n",
    "m.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluate your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Accuracy, Precision, Recall, F1, DummyClassifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8269230769230769"
      ]
     },
     "execution_count": 1409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(model.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7983870967741935"
      ]
     },
     "execution_count": 1410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_score(model.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7734375"
      ]
     },
     "execution_count": 1411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall_score(model.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7857142857142857"
      ]
     },
     "execution_count": 1412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(model.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6025641025641025"
      ]
     },
     "execution_count": 1413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf.fit(model.predict(X_train), y_train)\n",
    "accuracy_score(dummy_clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5288461538461539"
      ]
     },
     "execution_count": 1414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy='stratified')\n",
    "dummy_clf.fit(model.predict(X_train), y_train)\n",
    "accuracy_score(dummy_clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4807692307692308"
      ]
     },
     "execution_count": 1415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy='uniform')\n",
    "dummy_clf.fit(model.predict(X_train), y_train)\n",
    "accuracy_score(dummy_clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
